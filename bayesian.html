<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Bayesian Inference</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="bayesian_files/libs/clipboard/clipboard.min.js"></script>
<script src="bayesian_files/libs/quarto-html/quarto.js"></script>
<script src="bayesian_files/libs/quarto-html/popper.min.js"></script>
<script src="bayesian_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="bayesian_files/libs/quarto-html/anchor.min.js"></script>
<link href="bayesian_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="bayesian_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="bayesian_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="bayesian_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="bayesian_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Bayesian Inference</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pymc <span class="im">as</span> pm</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> config</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You can add options to executable code like this</p>
<pre class="{r}"><code>#| echo: false
2 * 2</code></pre>
<p>The <code>echo: false</code> option disables the printing of code (only output is displayed).</p>
<section id="statistical-inference" class="level2">
<h2 class="anchored" data-anchor-id="statistical-inference">Statistical Inference</h2>
<p>Statistical inference is the process in which we make inferences (estimates) about a population or problem space when we only have a sub-sample of the total probable outcomes. In the vast majority of cases, we can never collect data for the entire population of the problem space but instead can only sample a subset.</p>
<p>For example, some classic problems would be estimating the average height of everyone on earth when we only have the heights of 200 people or determining what is the probability of loan defaults for all potential loan customers given that I have 200 customers and 2 have defaulted in the last year. Another example closer to home would be using the daily returns of a stock or futures contract form the last 2 years (our sample) to estimate the population of ALL possible daily returns - most likely used to model the returns of the stock on contract going forward in time.</p>
<p>There are broadly two main approaches to making estimates about a population given data from a sub-sample from the population, a frequentist approach and a Bayesian approach.</p>
</section>
<section id="frequestist-approach" class="level2">
<h2 class="anchored" data-anchor-id="frequestist-approach">Frequestist Approach</h2>
<p>First lets define frequentist statistics. A frequentist approach to statistics is concerned with calculating the long-run probability of an outcome or event. This is the method that you were taught in school involving a lot of math, probabilities and p-values. The implicit assumption that we’re making with this approach is that we have some ability to determine the long-run probability of an outcome. For example the long-run probability of getting heads on a coin toss would be 0.5 based on what we know about the mechanics of a coin toss. However, what if thought that the coin might not be a “fair” coin? How would we arrive at the probability of heads then if we had data on tosses of that coin?</p>
<p>A frequentist approach to solving this problem (also called frequentist inference) would be to create a hypothesis and test it.</p>
<p>https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;ved=2ahUKEwjRpbe58qH3AhWCM30KHaWkDREQFnoECBsQAw&amp;url=https%3A%2F%2Fvault.hanover.edu%2F~altermattw%2Fcourses%2F220%2Freadings%2FStatistical_Inference.pdf&amp;usg=AOvVaw1htPlxgll-9LxipNreRcQQ</p>
<p>First we’re going to generate a sequence of 100 coin tosses using an unfair coin.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> config.p2</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>ntoss <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.RandomState(<span class="dv">13</span>) <span class="co">#15 for 40</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> rng.binomial(n<span class="op">=</span><span class="dv">1</span>, size<span class="op">=</span>ntoss, p<span class="op">=</span>p)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>heads <span class="op">=</span> data.<span class="bu">sum</span>()</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of heads in sample: "</span>, heads)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of heads in sample:  61</code></pre>
</div>
</div>
<p>Next we have to create a null hypothesis which in our case is that the coin is a fair coin toss. The alternative hypothesis is that the probablity of heads is greater than 50% and thus unfair.</p>
<p>h0: p = 0.5 # the null hypothesis that the coin is fair…</p>
<p>h1: p &gt; 0.5 # the alternative hypothesis</p>
<p>The goal here is to accept or reject the null hypothesis by determining the odds of getting your result under the null hypothesis that the coin is fair.</p>
<p>Frequentist inference asks the question, what would be the likelihood of getting 61 heads on 100 coin tosses if the coin was fair? To do this, we’ll do the 100 tosses of the fair coin, 10,000 times to see how often we get 61 or more heads out of a hundred.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>nsamples <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Flip </span><span class="sc">{</span>ntoss<span class="sc">}</span><span class="ss"> coins, </span><span class="sc">{</span>nsamples<span class="sc">}</span><span class="ss"> times...</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>pop <span class="op">=</span> rng.binomial(n<span class="op">=</span><span class="dv">1</span>, size<span class="op">=</span>ntoss<span class="op">*</span>nsamples, p<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>sample <span class="op">=</span> rng.choice(pop, size<span class="op">=</span>(ntoss,nsamples))</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>cnt <span class="op">=</span> sample.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of heads for each sample of 100 tosses (first 20 samples):</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cnt[:<span class="dv">20</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Flip 100 coins, 10000 times...

Number of heads for each sample of 100 tosses (first 20 samples):

[46 46 54 59 52 45 54 55 58 47 64 44 46 56 47 54 50 52 48 50]</code></pre>
</div>
</div>
<p>Now let’s determine how many times we got 61 heads or more…</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"probability of getting </span><span class="sc">{</span>heads<span class="sc">}</span><span class="ss"> heads or more: "</span>, <span class="bu">round</span>(<span class="bu">len</span>(cnt[cnt <span class="op">&gt;=</span> heads])<span class="op">/</span>nsamples<span class="op">*</span><span class="dv">100</span>,<span class="dv">4</span>), <span class="st">"%"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>probability of getting 61 heads or more:  1.83 %</code></pre>
</div>
</div>
<p>Then, because the odds of getting 61 heads or more on a fair coin is only 1.83%, I would reject the null hypothesis h0 that the coin is fair. This is your p-value, the odds of getting this result under the null hypothesis. Note that most statisticians reject the null hypothesis if the p-value is less than 5%. We also call the p-value you false-positive rate - if the coin was fair it would only show 61 heads (and that the coin was unfair) 1.83% of the time, causing you to reject the null hypothesis.</p>
<p>However, there are a number of issues with using this approach.</p>
</section>
<section id="issue-1-just-because-the-result-is-unlikely-doesnt-make-it-impossible" class="level2">
<h2 class="anchored" data-anchor-id="issue-1-just-because-the-result-is-unlikely-doesnt-make-it-impossible">Issue #1: Just because the result is unlikely, doesn’t make it impossible</h2>
<p>Remember, even with the fair coin, we still got 61 or more heads 1.83% of the time. Also, even an unfair coin can sometimes produce results that would be indicative of a fair coin…</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.RandomState(<span class="dv">12</span>) <span class="co"># 15 for 40</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> rng.binomial(n<span class="op">=</span><span class="dv">1</span>, size<span class="op">=</span>ntoss, p<span class="op">=</span>p)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>heads <span class="op">=</span> data.<span class="bu">sum</span>()</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of heads in sample: "</span>, heads)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"probability of getting </span><span class="sc">{</span>heads<span class="sc">}</span><span class="ss"> heads or more: "</span>, <span class="bu">round</span>(<span class="bu">len</span>(cnt[cnt <span class="op">&gt;=</span> heads])<span class="op">/</span>nsamples<span class="op">*</span><span class="dv">100</span>,<span class="dv">4</span>) , <span class="st">"%"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of heads in sample:  57
probability of getting 57 heads or more:  10.08 %</code></pre>
</div>
</div>
<p>Even though we generated this sample using the same probability of heads of 0.6 as before, now we can’t reject the null hypothesis!</p>
</section>
<section id="issue-2-picking-the-right-hypothesises-is-hard" class="level2">
<h2 class="anchored" data-anchor-id="issue-2-picking-the-right-hypothesises-is-hard">Issue #2: Picking the right hypothesises is hard</h2>
<p>In the example above, just because we’ve rejected the null hypothesis, it doesn’t actually tell us what the true value of <code>p</code> is! For example another alternative hypothesis could be <code>p &lt; 0.5</code>. While this is a simple example with only 3 possible outcomes for p, there are many real life examples where there are many possible explanations aside from the null hypothesis.</p>
<p>h0: p = 0.5</p>
<p>h1: p &gt; 0.5</p>
<p>h2: p &lt; 0.5</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> config.p3</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.RandomState(<span class="dv">101</span>) <span class="co">#15 for 40</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> rng.binomial(n<span class="op">=</span><span class="dv">1</span>, size<span class="op">=</span>ntoss, p<span class="op">=</span>p)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>heads <span class="op">=</span> data.<span class="bu">sum</span>()</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of heads in sample: "</span>, heads)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"probability of getting </span><span class="sc">{</span>heads<span class="sc">}</span><span class="ss"> heads or more: "</span>, <span class="bu">round</span>(<span class="bu">len</span>(cnt[cnt <span class="op">&gt;=</span> heads])<span class="op">/</span>nsamples<span class="op">*</span><span class="dv">100</span>,<span class="dv">4</span>) , <span class="st">"%"</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>plt.hist(sample.mean(axis<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"2.5th Percentile = "</span> <span class="op">+</span> <span class="bu">str</span>(np.percentile(sample.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>), <span class="fl">2.5</span>)) <span class="op">+</span> <span class="st">" heads"</span>, </span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"97.5th Percentile = "</span> <span class="op">+</span> <span class="bu">str</span>(np.percentile(sample.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>), <span class="fl">97.5</span>)) <span class="op">+</span> <span class="st">" heads"</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of heads in sample:  42
probability of getting 42 heads or more:  95.39 %
2.5th Percentile = 40.0 heads 97.5th Percentile = 60.0 heads</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="bayesian_files/figure-html/cell-7-output-2.png" width="583" height="411"></p>
</div>
</div>
<p>In this case, without knowing the answer which alternative hypothesis would you use? Also it’s bad practice just keep on testing various hypothesizes. This is because even with a result that shows a p-value of &lt; 5%, this still means that you could randomly get a false-positive. The chance of getting a false-positive with a p-value of 5% on 20 tests is 100%! i.e.&nbsp;random chance alone will give you a false-positive if you just run enough tests…</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.RandomState(<span class="dv">10</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>,<span class="dv">20</span>):</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> rng.binomial(n<span class="op">=</span><span class="dv">1</span>, size<span class="op">=</span>ntoss, p<span class="op">=</span>p)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    heads <span class="op">=</span> data.<span class="bu">sum</span>()</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"probability of getting </span><span class="sc">{</span>heads<span class="sc">}</span><span class="ss"> heads or more: "</span>, <span class="bu">round</span>(<span class="bu">len</span>(cnt[cnt <span class="op">&gt;=</span> heads])<span class="op">/</span>nsamples<span class="op">*</span><span class="dv">100</span>,<span class="dv">4</span>) , <span class="st">"%"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>probability of getting 49 heads or more:  62.57 %
probability of getting 49 heads or more:  62.57 %
probability of getting 51 heads or more:  46.45 %
probability of getting 52 heads or more:  38.84 %
probability of getting 58 heads or more:  6.91 %
probability of getting 44 heads or more:  90.3 %
probability of getting 47 heads or more:  75.92 %
probability of getting 57 heads or more:  10.08 %
probability of getting 48 heads or more:  69.7 %
probability of getting 42 heads or more:  95.39 %
probability of getting 46 heads or more:  81.77 %
probability of getting 49 heads or more:  62.57 %
probability of getting 50 heads or more:  54.58 %
probability of getting 48 heads or more:  69.7 %
probability of getting 52 heads or more:  38.84 %
probability of getting 57 heads or more:  10.08 %
probability of getting 51 heads or more:  46.45 %
probability of getting 45 heads or more:  86.56 %
probability of getting 61 heads or more:  1.83 %
probability of getting 47 heads or more:  75.92 %</code></pre>
</div>
</div>
</section>
<section id="trying-to-determine-the-long-run-probability-does-not-always-make-sense" class="level2">
<h2 class="anchored" data-anchor-id="trying-to-determine-the-long-run-probability-does-not-always-make-sense">Trying to Determine the Long-run Probability Does Not Always Make Sense</h2>
<p>In many classes of problems, the concept of a long-run probability doesn’t always make sense. For example what is the long-run probability that our Sun will go nova tomorrow? How knows? We only have one sun and it’s never gone nova before!</p>
</section>
<section id="issues" class="level2">
<h2 class="anchored" data-anchor-id="issues">Issues</h2>
<p>So in summary, some issues with using a frequentist approach is that:</p>
<ol type="1">
<li>It does not tell you what the most likely answer is…</li>
<li>It does not tell you if p=0.5 is wrong, just unlikely. You can still get 9 heads with p=0.5. This is your false positive rate.</li>
<li>Long-run probabilities don’t always exist</li>
</ol>
<p>Note that what we’ve done above is not the true way to calculate the p-value as most statistical methods use formulas to calculate it vs simulations.</p>
<p>That’s not to say a frequentist approach is bad and in fact bayesian inference converges to the frequentist approach with sufficiently large samples. However let’s now have a look at Bayesian Inference.</p>
</section>
<section id="bayesian-approach" class="level2">
<h2 class="anchored" data-anchor-id="bayesian-approach">Bayesian Approach</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://imgs.xkcd.com/comics/frequentists_vs_bayesians_2x.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">https://xkcd.com/1132/</figcaption><p></p>
</figure>
</div>
<p>https://www.sciencedirect.com/topics/neuroscience/statistical-inference</p>
<p>https://en.wikipedia.org/wiki/Frequentist_inference</p>
<p>https://www.redjournal.org/article/S0360-3016(21)03256-9/fulltext</p>
<p>https://corporatefinanceinstitute.com/resources/knowledge/other/hypothesis-testing/</p>
<p>http://sellsidehandbook.com/2018/12/09/statistical-inference-and-hypothesis-testing/</p>
<p>https://www.statisticshowto.com/frequentist-statistics/</p>
<p>https://www.statisticshowto.com/bayesian-statistics/</p>
<p>https://stats.stackexchange.com/questions/2272/whats-the-difference-between-a-confidence-interval-and-a-credible-interval</p>
<p>https://www.amazon.ca/Introduction-Bayesian-Statistics-William-Bolstad/dp/1118091566</p>
<p>Bayesian inference and Bayesian statistics in general is named after the statistician Thomas Bayes.</p>
<p>In contrast to the frequentist method, Bayesian inference is focused on the probability that something is true. It begins with a measure of belief in a particular model or number, then with the addition of data, this belief is updated to reflect this new data. In my opinion, it is a more intuitive and natural method for incorporating data into the analytical process.</p>
<p>Let’s start with the same example as in the frequentist example, let’s say we have a coin and we want to determine if it’s fair. First let’s toss a single coin.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats <span class="im">as</span> stats</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># H = 1, T = 0</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> config.p2</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.RandomState(<span class="dv">13</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> rng.binomial(n<span class="op">=</span><span class="dv">1</span>, size<span class="op">=</span><span class="dv">10</span>, p<span class="op">=</span>p)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>array([0, 1, 0, 0, 0, 1, 0, 0, 0, 0])</code></pre>
</div>
</div>
<p>Based on this sequence, what is the most probable value of p? A bayesian approach would ask how often would this sequence of data occur if p was 0.5? If it was 0.6? If it was 0.7? etc. We can then use this information to determine the most likely value of p.&nbsp;</p>
<p>To start, we will try a range of values for p from 0.1 to 0.9 and flip the coin 10 times to generate a sample. We will then repeat this sample of 10 flips 100 times to see how often we see 2 heads for each value of p.</p>
<p>First we will run with <code>p=0.1</code>.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.RandomState(<span class="dv">13</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>ps <span class="op">=</span> [<span class="fl">0.1</span>,<span class="fl">0.2</span>,<span class="fl">0.3</span>,<span class="fl">0.4</span>,<span class="fl">0.5</span>,<span class="fl">0.6</span>,<span class="fl">0.7</span>,<span class="fl">0.8</span>,<span class="fl">0.9</span>]</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>cnt <span class="op">=</span> np.array([<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>])</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>,<span class="dv">1000</span>):</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>  tmp <span class="op">=</span> rng.binomial(n<span class="op">=</span><span class="dv">1</span>, size<span class="op">=</span><span class="dv">10</span>, p<span class="op">=</span>p)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> tmp.<span class="bu">sum</span>() <span class="op">==</span> data.<span class="bu">sum</span>():</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    cnt[<span class="dv">0</span>] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>ax.bar(x<span class="op">=</span>ps, height<span class="op">=</span>cnt, width<span class="op">=</span><span class="fl">0.1</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="bayesian_files/figure-html/cell-10-output-1.png" width="575" height="411"></p>
</div>
</div>
<p>Now let’s run it again for <code>p=0.2</code> so see how often we get 2 heads.</p>
<div class="cell" data-execution_count="10">
<div class="cell-output cell-output-display">
<p><img src="bayesian_files/figure-html/cell-11-output-1.png" width="575" height="411"></p>
</div>
</div>
<p>Finally we will run it for all values for <code>p</code> between 0.1 and 0.9.</p>
<div class="cell" data-execution_count="11">
<div class="cell-output cell-output-display">
<p><img src="bayesian_files/figure-html/cell-12-output-1.png" width="575" height="411"></p>
</div>
</div>
<p>This now gives us the number of times that 1000 draws of 10 coin tosses would give us 2 heads for each value of <code>p</code>. In other words we now have a probabiility distribution for the value of <code>p</code> given the data that we have (i.e.&nbsp;2 heads out of 10 coin tosses). This is the essence of bayesian inference, basically counting. Where we make some assumption on the underlying data generating process and given this <em>a priori</em> assumption, we determine how likely each parameter is in generating the data that we see.</p>
<p>So what we did in summary was:</p>
<ol type="1">
<li>View the data and assumed that the underlying data generating process was a bionomial distribution.</li>
<li>For each value of <code>p</code>, determine what is the liklihood of getting 2 heads out of 10.</li>
<li>Put this together in a postierior distribution for <code>p</code>. This is our estimate for <code>p</code> with our uncertainty built it.</li>
</ol>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>dist <span class="op">=</span> stats.beta</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> config.p2 </span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>ntoss <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.RandomState(<span class="dv">13</span>) <span class="co">#15 for 40</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> rng.binomial(n<span class="op">=</span><span class="dv">1</span>, size<span class="op">=</span>ntoss, p<span class="op">=</span>p)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>heads <span class="op">=</span> data.<span class="bu">sum</span>()</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>n_trials <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">50</span>, <span class="dv">100</span>]</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># For the already prepared, I'm using Binomial's conj. prior.</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, N <span class="kw">in</span> <span class="bu">enumerate</span>(n_trials):</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    sx <span class="op">=</span> plt.subplot(<span class="bu">len</span>(n_trials)<span class="op">//</span><span class="dv">2</span>, <span class="dv">2</span>, k<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"$p$, probability of heads"</span>) <span class="op">\</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> k <span class="kw">in</span> [<span class="dv">0</span>, <span class="bu">len</span>(n_trials)<span class="op">-</span><span class="dv">1</span>] <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    plt.setp(sx.get_yticklabels(), visible<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    heads <span class="op">=</span> data[:N].<span class="bu">sum</span>()</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> dist.pdf(x, <span class="dv">1</span> <span class="op">+</span> heads, <span class="dv">1</span> <span class="op">+</span> N <span class="op">-</span> heads)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    plt.plot(x, y, label<span class="op">=</span><span class="st">"observe </span><span class="sc">%d</span><span class="st"> tosses,</span><span class="ch">\n</span><span class="st"> </span><span class="sc">%d</span><span class="st"> heads"</span> <span class="op">%</span> (N, heads))</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    plt.fill_between(x, <span class="dv">0</span>, y, color<span class="op">=</span><span class="st">"#348ABD"</span>, alpha<span class="op">=</span><span class="fl">0.4</span>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    plt.vlines(<span class="fl">0.5</span>, <span class="dv">0</span>, <span class="dv">4</span>, color<span class="op">=</span><span class="st">"k"</span>, linestyles<span class="op">=</span><span class="st">"--"</span>, lw<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>    leg <span class="op">=</span> plt.legend()</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    leg.get_frame().set_alpha(<span class="fl">0.4</span>)</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    plt.autoscale(tight<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="bayesian_files/figure-html/cell-14-output-1.png" width="662" height="468"></p>
</div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> config.p2</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>ntoss <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.RandomState(<span class="dv">13</span>) <span class="co">#15 for 40</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> rng.binomial(n<span class="op">=</span><span class="dv">1</span>, size<span class="op">=</span>ntoss, p<span class="op">=</span>p)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>heads <span class="op">=</span> data.<span class="bu">sum</span>()</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of heads in sample: "</span>, heads)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"First 10 coin tosses: "</span>, data[:<span class="dv">10</span>], <span class="st">"..."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of heads in sample:  61
First 10 coin tosses:  [0 1 0 0 0 1 0 0 0 0] ...</code></pre>
</div>
</div>
<p>With the first toss we would have no data and so we would have what we call an uniformed prior. Thus, any value for <code>p</code> is equally likely.</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>