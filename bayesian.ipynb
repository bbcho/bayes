{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Bayesian Inference\n",
        "execute:\n",
        "  echo: true\n",
        "---"
      ],
      "id": "b2ee12b6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pymc as pm\n",
        "import config"
      ],
      "id": "a30e28b6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can add options to executable code like this\n",
        "\n",
        "\n",
        "```{r}\n",
        "#| echo: false\n",
        "2 * 2\n",
        "```\n",
        "\n",
        "\n",
        "The `echo: false` option disables the printing of code (only output is displayed).\n",
        "\n",
        "## Statistical Inference\n",
        "\n",
        "Statistical inference is the process in which we make inferences (estimates) about a population or problem space when we only have a sub-sample of the total probable outcomes. In the vast majority of cases, we can never collect data for the entire population of the problem space but instead can only sample a subset.\n",
        "\n",
        "For example, some classic problems would be estimating the average height of everyone on earth when we only have the heights of 200 people or determining what is the probability of loan defaults for all potential loan customers given that I have 200 customers and 2 have defaulted in the last year. Another example closer to home would be using the daily returns of a stock or futures contract form the last 2 years (our sample) to estimate the population of ALL possible daily returns - most likely used to model the returns of the stock on contract going forward in time.\n",
        "\n",
        "There are broadly two main approaches to making estimates about a population given data from a sub-sample from the population, a frequentist approach and a Bayesian approach.\n",
        "\n",
        "## Frequestist Approach\n",
        "\n",
        "First lets define frequentist statistics. A frequentist approach to statistics is concerned with calculating the long-run probability of an outcome or event. This is the method that you were taught in school involving a lot of math, probabilities and p-values. The implicit assumption that we're making with this approach is that we have some ability to determine the long-run probability of an outcome. For example the long-run probability of getting heads on a coin toss would be 0.5 based on what we know about the mechanics of a coin toss. However, what if thought that the coin might not be a \"fair\" coin? How would we arrive at the probability of heads then if we had data on tosses of that coin?\n",
        "\n",
        "A frequentist approach to solving this problem (also called frequentist inference) would be to create a hypothesis and test it.\n",
        "\n",
        "https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwjRpbe58qH3AhWCM30KHaWkDREQFnoECBsQAw&url=https%3A%2F%2Fvault.hanover.edu%2F~altermattw%2Fcourses%2F220%2Freadings%2FStatistical_Inference.pdf&usg=AOvVaw1htPlxgll-9LxipNreRcQQ\n",
        "\n",
        "First we're going to generate a sequence of 100 coin tosses using an unfair coin.\n"
      ],
      "id": "40dad0bb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "p = config.p2\n",
        "ntoss = 100\n",
        "\n",
        "rng = np.random.RandomState(13) #15 for 40\n",
        "data = rng.binomial(n=1, size=ntoss, p=p)\n",
        "heads = data.sum()\n",
        "print(\"Number of heads in sample: \", heads)"
      ],
      "id": "8cdb95fb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we have to create a null hypothesis which in our case is that the coin is a fair coin toss. The alternative hypothesis is that the probablity of heads is greater than 50% and thus unfair.\n",
        "\n",
        "h0: p = 0.5 # the null hypothesis that the coin is fair...\n",
        "\n",
        "h1: p > 0.5 # the alternative hypothesis \n",
        "\n",
        "The goal here is to accept or reject the null hypothesis by determining the odds of getting your result under the null hypothesis that the coin is fair.\n",
        "\n",
        "Frequentist inference asks the question, what would be the likelihood of getting 61 heads on 100 coin tosses if the coin was fair? To do this, we'll do the 100 tosses of the fair coin, 10,000 times to see how often we get 61 or more heads out of a hundred.\n"
      ],
      "id": "e86636f8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "nsamples = 10000\n",
        "\n",
        "print(f\"Flip {ntoss} coins, {nsamples} times...\\n\")\n",
        "\n",
        "pop = rng.binomial(n=1, size=ntoss*nsamples, p=0.5)\n",
        "sample = rng.choice(pop, size=(ntoss,nsamples))\n",
        "\n",
        "cnt = sample.sum(axis=0)\n",
        "\n",
        "print(\"Number of heads for each sample of 100 tosses (first 20 samples):\\n\")\n",
        "print(cnt[:20])"
      ],
      "id": "8cfd5b52",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's determine how many times we got 61 heads or more...\n"
      ],
      "id": "24925a83"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"probability of getting {heads} heads or more: \", round(len(cnt[cnt >= heads])/nsamples*100,4), \"%\")"
      ],
      "id": "b38559a5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, because the odds of getting 61 heads or more on a fair coin is only 1.83%, I would reject the null hypothesis h0 that the coin is fair. This is your p-value, the odds of getting this result under the null hypothesis. Note that most statisticians reject the null hypothesis if the p-value is less than 5%. We also call the p-value you false-positive rate - if the coin was fair it would only show 61 heads (and that the coin was unfair) 1.83% of the time, causing you to reject the null hypothesis.\n",
        "\n",
        "However, there are a number of issues with using this approach.\n",
        "\n",
        "## Issue #1: Just because the result is unlikely, doesn't make it impossible\n",
        "\n",
        "Remember, even with the fair coin, we still got 61 or more heads 1.83% of the time. Also, even an unfair coin can sometimes produce results that would be indicative of a fair coin... \n"
      ],
      "id": "c94df7b1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rng = np.random.RandomState(12) # 15 for 40\n",
        "data = rng.binomial(n=1, size=ntoss, p=p)\n",
        "heads = data.sum()\n",
        "print(\"Number of heads in sample: \", heads)\n",
        "\n",
        "print(f\"probability of getting {heads} heads or more: \", round(len(cnt[cnt >= heads])/nsamples*100,4) , \"%\")"
      ],
      "id": "7cb8882a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Even though we generated this sample using the same probability of heads of 0.6 as before, now we can't reject the null hypothesis!\n",
        "\n",
        "## Issue #2: Picking the right hypothesises is hard\n",
        "\n",
        "In the example above, just because we've rejected the null hypothesis, it doesn't actually tell us what the true value of `p` is! For example another alternative hypothesis could be `p < 0.5`. While this is a simple example with only 3 possible outcomes for p, there are many real life examples where there are many possible explanations aside from the null hypothesis.\n",
        "\n",
        "h0: p = 0.5\n",
        "\n",
        "h1: p > 0.5\n",
        "\n",
        "h2: p < 0.5\n"
      ],
      "id": "07393e55"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "p = config.p3\n",
        "\n",
        "rng = np.random.RandomState(101) #15 for 40\n",
        "data = rng.binomial(n=1, size=ntoss, p=p)\n",
        "heads = data.sum()\n",
        "print(\"Number of heads in sample: \", heads)\n",
        "\n",
        "print(f\"probability of getting {heads} heads or more: \", round(len(cnt[cnt >= heads])/nsamples*100,4) , \"%\")\n",
        "\n",
        "plt.hist(sample.mean(axis=0))\n",
        "print(\n",
        "    \"2.5th Percentile = \" + str(np.percentile(sample.sum(axis=0), 2.5)) + \" heads\", \n",
        "    \"97.5th Percentile = \" + str(np.percentile(sample.sum(axis=0), 97.5)) + \" heads\"\n",
        "    )"
      ],
      "id": "15cbee49",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this case, without knowing the answer which alternative hypothesis would you use? Also it's bad practice just keep on testing various hypothesizes. This is because even with a result that shows a p-value of < 5%, this still means that you could randomly get a false-positive. The chance of getting a false-positive with a p-value of 5% on 20 tests is 100%! i.e. random chance alone will give you a false-positive if you just run enough tests...\n"
      ],
      "id": "c8f0119e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "p = 0.5\n",
        "rng = np.random.RandomState(10)\n",
        "\n",
        "\n",
        "for i in range(0,20):\n",
        "    data = rng.binomial(n=1, size=ntoss, p=p)\n",
        "    heads = data.sum()\n",
        "\n",
        "    print(f\"probability of getting {heads} heads or more: \", round(len(cnt[cnt >= heads])/nsamples*100,4) , \"%\")"
      ],
      "id": "bf194d2b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trying to Determine the Long-run Probability Does Not Always Make Sense\n",
        "\n",
        "In many classes of problems, the concept of a long-run probability doesn't always make sense. For example what is the long-run probability that our Sun will go nova tomorrow? How knows? We only have one sun and it's never gone nova before!\n",
        "\n",
        "## Issues\n",
        "\n",
        "So in summary, some issues with using a frequentist approach is that:\n",
        "\n",
        "1. It does not tell you what the most likely answer is...\n",
        "1. It does not tell you if p=0.5 is wrong, just unlikely. You can still get 9 heads with p=0.5. This is your false positive rate.\n",
        "1. Long-run probabilities don't always exist\n",
        "\n",
        "Note that what we've done above is not the true way to calculate the p-value as most statistical methods use formulas to calculate it vs simulations.\n",
        "\n",
        "That's not to say a frequentist approach is bad and in fact bayesian inference converges to the frequentist approach with sufficiently large samples. However let's now have a look at Bayesian Inference.\n",
        "\n",
        "## Bayesian Approach\n",
        "\n",
        "![https://xkcd.com/1132/](https://imgs.xkcd.com/comics/frequentists_vs_bayesians_2x.png)\n",
        "\n",
        "\n",
        "https://www.sciencedirect.com/topics/neuroscience/statistical-inference\n",
        "\n",
        "https://en.wikipedia.org/wiki/Frequentist_inference\n",
        "\n",
        "https://www.redjournal.org/article/S0360-3016(21)03256-9/fulltext\n",
        "\n",
        "https://corporatefinanceinstitute.com/resources/knowledge/other/hypothesis-testing/\n",
        "\n",
        "http://sellsidehandbook.com/2018/12/09/statistical-inference-and-hypothesis-testing/\n",
        "\n",
        "https://www.statisticshowto.com/frequentist-statistics/\n",
        "\n",
        "https://www.statisticshowto.com/bayesian-statistics/\n",
        "\n",
        "https://stats.stackexchange.com/questions/2272/whats-the-difference-between-a-confidence-interval-and-a-credible-interval\n",
        "\n",
        "https://www.amazon.ca/Introduction-Bayesian-Statistics-William-Bolstad/dp/1118091566\n",
        "\n",
        "Bayesian inference and Bayesian statistics in general is named after the statistician Thomas Bayes.\n",
        "\n",
        "In contrast to the frequentist method, Bayesian inference is focused on the probability that something is true. It asks the question, \"what do I think is the underlying data generating process\" and then uses this to determine the probability of the data given the model. \n",
        "\n",
        "It begins with a measure of belief in a particular model or number, then with the addition of data, this belief is updated to reflect this new data. In my opinion, it is a more intuitive and natural method for incorporating data into the analytical process.\n",
        "\n",
        "The general recipe for Bayesian inference is:\n",
        "\n",
        "1. Pick a model that could have generated the data that you see (i.e. linear model, binomial distribution etc...)\n",
        "2. Pick a prior distribution for the parameters of the model based on your knowledge of the process if any (this can also be uninformed).\n",
        "3. Count the number of ways that your assumed model could have generated your data for each value of your parameter(s).\n",
        "4. Parameters with more ways to produce your data are more plausible - put this together in a posterior distribution for your parameters.\n",
        "\n",
        "Let's start with the same example as in the frequentist example, let's say we have a coin and we want to determine if it's fair. First let's toss a single coin.\n"
      ],
      "id": "53da7e3c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# H = 1, T = 0\n",
        "p = config.p2\n",
        "\n",
        "rng = np.random.RandomState(13)\n",
        "data = rng.binomial(n=1, size=10, p=p)\n",
        "data"
      ],
      "id": "ce949461",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on this sequence, what is the most probable value of p? A bayesian approach would ask how often would this sequence of data occur if p was 0.5? If it was 0.6? If it was 0.7? etc. We can then use this information to determine the most likely value of p. \n",
        "\n",
        "To start, we will try a range of values for p from 0.1 to 0.9 and flip the coin 10 times to generate a sample. We will then repeat this sample of 10 flips 100 times to see how often we see 2 heads for each value of p.\n",
        "\n",
        "First we will run with `p=0.1`.\n"
      ],
      "id": "49cf1ee0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "p = 0.1\n",
        "\n",
        "rng = np.random.RandomState(13)\n",
        "ps = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
        "cnt = np.array([0,0,0,0,0,0,0,0,0])\n",
        "\n",
        "for i in range(0,1000):\n",
        "  tmp = rng.binomial(n=1, size=10, p=p)\n",
        "  if tmp.sum() == data.sum():\n",
        "    cnt[0] += 1\n",
        "\n",
        "fig, ax = plt.subplots(1,1)\n",
        "\n",
        "ax.bar(x=ps, height=cnt, width=0.1);"
      ],
      "id": "1b76743e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's run it again for `p=0.2` so see how often we get 2 heads.\n"
      ],
      "id": "62b4b142"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "p = 0.2\n",
        "\n",
        "for i in range(0,1000):\n",
        "  tmp = rng.binomial(n=1, size=10, p=p)\n",
        "  if tmp.sum() == data.sum():\n",
        "    cnt[1] += 1\n",
        "\n",
        "fig, ax = plt.subplots(1,1)\n",
        "\n",
        "ax.bar(x=ps, height=cnt, width=0.1);"
      ],
      "id": "d7ae3bbf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally we will run it for all values for `p` between 0.1 and 0.9.\n"
      ],
      "id": "33ae2190"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "cnt = np.array([0,0,0,0,0,0,0,0,0])\n",
        "\n",
        "for j in ps:\n",
        "  p = j\n",
        "  idx = ps.index(p)\n",
        "\n",
        "  for i in range(0,1000):\n",
        "    tmp = rng.binomial(n=1, size=10, p=p)\n",
        "    if tmp.sum() == data.sum():\n",
        "      cnt[idx] += 1\n",
        "\n",
        "fig, ax = plt.subplots(1,1)\n",
        "\n",
        "ax.bar(x=ps, height=cnt, width=0.1);"
      ],
      "id": "6d7da864",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This now gives us the number of times that 1000 draws of 10 coin tosses would give us 2 heads for each value of `p`. In other words we now have a probabiility distribution for the value of `p` given the data that we have (i.e. 2 heads out of 10 coin tosses). This is the essence of bayesian inference, basically counting. Where we make some assumption on the underlying data generating process and given this *a priori* assumption, we determine how likely each parameter is in generating the data that we see.  \n",
        "\n",
        "What we did was:\n",
        "\n",
        "1. I think the underlying data generating process is a binomial distribution.\n",
        "2. However, I do not know what the value of `p` is so I'm going to try all values of `p` (uninformed prior).\n",
        "3. For each value of `p`, I counted all the ways that my process can generate the data that I see.\n",
        "4. Put this together into a posterior distribution for `p`. Values of `p` with more ways to produce my data are more plausible. This is my estimate for `p` with my uncertainty built it.\n",
        "\n",
        "I'm now going to introduce you to a slightly easier way for us to perform that same calculation. The issue with the above is that it is computationally expensive and hard to update with new data without rerunning the whole thing. \n"
      ],
      "id": "6325620b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n_trials = [0, 1, 2, 3, 10, 20, 50, 100]\n",
        "x = np.linspace(0, 1, 100)\n",
        "\n",
        "# For the already prepared, I'm using Binomial's conj. prior.\n",
        "for k, N in enumerate(n_trials):\n",
        "    sx = plt.subplot(len(n_trials)//2, 2, k+1)\n",
        "    plt.xlabel(\"$p$, probability of heads\") \\\n",
        "        if k in [0, len(n_trials)-1] else None\n",
        "    plt.setp(sx.get_yticklabels(), visible=False)\n",
        "    heads = data[:N].sum()\n",
        "    y = dist.pdf(x, 1 + heads, 1 + N - heads)\n",
        "    plt.plot(x, y, label=\"observe %d tosses,\\n %d heads\" % (N, heads))\n",
        "    plt.fill_between(x, 0, y, color=\"#348ABD\", alpha=0.4)\n",
        "    plt.vlines(0.5, 0, 4, color=\"k\", linestyles=\"--\", lw=1)\n",
        "\n",
        "    leg = plt.legend()\n",
        "    leg.get_frame().set_alpha(0.4)\n",
        "    plt.autoscale(tight=True)\n",
        "\n",
        "plt.tight_layout()"
      ],
      "id": "300d8508",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "p = config.p2\n",
        "ntoss = 100\n",
        "\n",
        "rng = np.random.RandomState(13) #15 for 40\n",
        "data = rng.binomial(n=1, size=ntoss, p=p)\n",
        "heads = data.sum()\n",
        "print(\"Number of heads in sample: \", heads)\n",
        "print(\"First 10 coin tosses: \", data[:10], \"...\")"
      ],
      "id": "7cd4e39b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the first toss we would have no data and so we would have what we call an uniformed prior. Thus, any value for `p` is equally likely."
      ],
      "id": "98afd368"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}